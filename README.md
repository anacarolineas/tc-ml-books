# TC ML Books

Uma API RESTful baseada em FastAPI para consulta de livros, categorias, previsÃµes de machine learning e cadastro de usuÃ¡rios. 
Os dados disponÃ­veis para essa API foram extraÃ­dos do site [books.toscrape](https://books.toscrape.com/).

## Funcionalidades

- ğŸ“š Busca e filtragem de livros e suas categorias
- ğŸ‘¤ AutenticaÃ§Ã£o de usuÃ¡rios (JWT)
- ğŸ“Š Endpoints de estatÃ­sticas (visÃ£o geral, categorias)
- ğŸ¤– Endpoints de Machine Learning (features, dados de treino, previsÃµes)
- ğŸ©º Endpoint de helth check
- ğŸ–¥ï¸ Scraper de livros do site [books.toscrape](https://books.toscrape.com/)

## Tecnologias

- Python 3.12+
- FastAPI
- SQLAlchemy
- Pydantic
- UV (gerenciador de projeto)
- SQLite
- Docker
- BeautifulSoup

## Estrutura do Projeto

```
tc-ml-books/
â”œâ”€â”€ dashboard/         # Dashboard para anÃ¡lise de dados
â”œâ”€â”€ docs/              # Outras documentaÃ§Ãµes, plano arquitetural
â”œâ”€â”€ pipelines/         # CI/CD, GitHub Actions 
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/           # Handlers das rotas FastAPI
â”‚   â”œâ”€â”€ core/          # UtilitÃ¡rios, configuraÃ§Ã£o, seguranÃ§a
â”‚   â”œâ”€â”€ crud/          # LÃ³gica de acesso ao banco de dados
â”‚   â”œâ”€â”€ data/          # Arquivos gerados pelo scrape
â”‚   â”œâ”€â”€ middlewares/   # Logs e rate limit
â”‚   â”œâ”€â”€ models/        # Modelos SQLAlchemy
â”‚   â”œâ”€â”€ schemas/       # Schemas Pydantic
â”‚   â”œâ”€â”€ scripts/       # Scripts para scraper e carga inicial da base
â”‚   â””â”€â”€ main.py        # Ponto de entrada da aplicaÃ§Ã£o FastAPI
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ pyproject.toml     # DependÃªncias do projeto
â”œâ”€â”€ README.md
â””â”€â”€ ...
```

## Primeiros Passos

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/seu-usuario/tc-ml-books.git
cd tc-ml-books
```

### 2. Instale as dependÃªncias

#### 2.1. Instalar UV
```bash
pip install uv
```
Outros meios de instalaÃ§Ã£o: [DocumentaÃ§Ã£o UV](https://docs.astral.sh/uv/getting-started/installation/).

#### 2.2. InstalaÃ§Ã£o das dependÃªncias utilizando comandos UV
Linux
```bash
uv venv
source .venv/bin/activate
uv pip sync pyproject.toml
```
Windows
```bash
uv venv
.\venv\Scripts\activate
uv pip sync pyproject.toml
```

### 3. Configure as variÃ¡veis de ambiente

Crie um arquivo `.env` na raiz do projeto:

```
DATABASE_URL=sqlite:///./nome-banco.db
SECRET_KEY=sua-chave-secreta
```

### 4. Execute as migraÃ§Ãµes do banco de dados

```bash
alembic upgrade head
```

### 5. Inicie a API

```bash
uv run uvicorn main:app --reload
```

A API estarÃ¡ disponÃ­vel em [http://localhost:8000](http://localhost:8000).

## DocumentaÃ§Ã£o da API

DocumentaÃ§Ã£o disponÃ­vel em:

- [Swagger UI](http://localhost:8000/docs)
- [ReDoc](http://localhost:8000/redoc)

## Exemplos de Uso

### Listar todos os livros

```http
GET /api/books/
```

### Obter estatÃ­sticas dos livros

```http
GET /api/stats/overview
```

### Obter features de ML para um livro

```http
GET /api/ml/features/{book_id}
```

## Docker (opcional)

Construa e rode com Docker:

```bash
docker build -t tc-ml-books .
docker run -p 8000:8000 tc-ml-books
```

## Executando Scripts de Scraper e Seed

### 1. Rodar o Scraper

O script de scraper coleta os dados de livros do site [books.toscrape](https://books.toscrape.com/) e salva em um arquivo na pasta `src/data/`. O script tambÃ©m gera um arquivo de log `log_scraping.txt` detalhado de execuÃ§Ã£o nessa mesma pasta.

Execute o comando:

```bash
uv run python src/scripts/bookstoscrape_scraper.py
```

### 2. Rodar o Seed (Carga Inicial)

ApÃ³s rodar o scraper, utilize o script de seed para popular o banco de dados com os dados coletados:

```bash
uv run python -m src.scripts.scrape_books
```

Certifique-se de que as variÃ¡veis de ambiente estejam configuradas e que o ambiente virtual esteja ativado antes de executar os scripts.

## LicenÃ§a

MIT License

---

