# Tech Challenge ENG. Machine Learning - Scrapper Livros + Pipeline de dados

Uma API RESTful baseada em FastAPI para consulta de livros, categorias, previsÃµes de machine learning e cadastro de usuÃ¡rios. Os dados disponÃ­veis para essa API foram extraÃ­dos do site [books.toscrape](https://books.toscrape.com/).

## Funcionalidades

- ğŸ“š Busca e filtragem de livros e suas categorias
- ğŸ‘¤ AutenticaÃ§Ã£o de usuÃ¡rios (JWT)
- ğŸ“Š Endpoints de estatÃ­sticas (visÃ£o geral, categorias)
- ğŸ¤– Endpoints de Machine Learning (features, dados de treino, previsÃµes)
- ğŸ©º Endpoint de helth check
- ğŸ–¥ï¸ Scraper de livros do site [books.toscrape](https://books.toscrape.com/)

## Tecnologias

- Python 3.12+
- FastAPI
- SQLAlchemy
- Pydantic
- UV (gerenciador de projeto)
- SQLite
- Docker
- BeautifulSoup

## Estrutura do Projeto

```
tc-ml-books/
â”œâ”€â”€ dashboard/         # Dashboard para anÃ¡lise de dados
â”œâ”€â”€ docs/              # Outras documentaÃ§Ãµes, plano arquitetural
â”œâ”€â”€ pipelines/         # CI/CD, GitHub Actions 
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/           # Handlers das rotas FastAPI
â”‚   â”œâ”€â”€ core/          # UtilitÃ¡rios, configuraÃ§Ã£o, seguranÃ§a
â”‚   â”œâ”€â”€ crud/          # LÃ³gica de acesso ao banco de dados
â”‚   â”œâ”€â”€ data/          # Arquivos gerados pelo scrape
â”‚   â”œâ”€â”€ middlewares/   # CentralizaÃ§Ã£o logs
â”‚   â”œâ”€â”€ models/        # Modelos SQLAlchemy
â”‚   â”œâ”€â”€ schemas/       # Schemas Pydantic
â”‚   â”œâ”€â”€ scripts/       # Scripts para scraper e carga inicial da base
â”‚   â””â”€â”€ main.py        # Ponto de entrada da aplicaÃ§Ã£o FastAPI
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ pyproject.toml     # DependÃªncias do projeto
â”œâ”€â”€ README.md
â””â”€â”€ ...
```

## Primeiros Passos

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/seu-usuario/tc-ml-books.git
cd tc-ml-books
```

### 2. Instale as dependÃªncias

#### 2.1. Instalar UV
```bash
pip install uv
```
Outros formas de instalaÃ§Ã£o: [DocumentaÃ§Ã£o UV](https://docs.astral.sh/uv/getting-started/installation/).

#### 2.2. InstalaÃ§Ã£o das dependÃªncias utilizando comandos UV
Linux
```bash
uv venv
source .venv/bin/activate
uv pip sync pyproject.toml
```
Windows
```bash
uv venv
.\venv\Scripts\activate
uv pip sync pyproject.toml
```

### 3. Configure as variÃ¡veis de ambiente

Crie um arquivo `.env` na raiz do projeto:

```
DATABASE_URL=sqlite:///./nome-banco.db
SECRET_KEY=sua-chave-secreta
```

### 4. Execute as migraÃ§Ãµes do banco de dados

```bash
alembic upgrade head
```

### 5. Inicie a API

```bash
uv run uvicorn main:app --reload
```

A API estarÃ¡ disponÃ­vel em [http://localhost:8000](http://localhost:8000).

## DocumentaÃ§Ã£o da API

DocumentaÃ§Ã£o disponÃ­vel em:

- [Swagger UI](http://localhost:8000/docs)
- [ReDoc](http://localhost:8000/redoc)

## Exemplos de Uso

### Listar todos os livros

```http
GET /api/books/
```

### Obter estatÃ­sticas dos livros

```http
GET /api/stats/overview
```

### Obter features de ML para um livro

```http
GET /api/ml/features/{book_id}
```

## Docker (opcional)

Construa e rode com Docker:

```bash
docker build -t tc-ml-books .
docker run -p 8000:8000 tc-ml-books
```

## Executando Scripts de Scraper e Seed

### 1. Rodar o Scraper

O script de scraper coleta os dados de livros do site [books.toscrape](https://books.toscrape.com/) e salva em um arquivo na pasta `src/data/`. Um arquivo de log `log_scraping.txt` Ã© gerado, detalhando sua execuÃ§Ã£o.

Execute o comando:

```bash
uv run python src/scripts/bookstoscrape_scraper.py
```

### 2. Rodar o Seed (Carga Inicial)

ApÃ³s rodar o scraper, utilize o script de seed para popular o banco de dados com os dados coletados:

```bash
uv run -m src.scripts.seed
```
Um arquivo de log `log_seed.txt` Ã© gerado, detalhando sua execuÃ§Ã£o.

Certifique-se de que as variÃ¡veis de ambiente estejam configuradas e que o ambiente virtual esteja ativado antes de executar os scripts.

`Obs`.: ao rodar o script, todos os registros de livros e categorias sÃ£o apagados antes dos novos serem inseridos.

## Dashboard
Dashboard interativo construÃ­do com `Streamlit` para exploraÃ§Ã£o da base de livros. A aplicaÃ§Ã£o foi projetada para consumir a API RESTful buscando dados em tempo real e garantindo o acesso atravÃ©s de uma tela de login segura. Dessa forma, para rodar o dashboard, a API deverÃ¡ estar em execuÃ§Ã£o.

Execute o comando:

```bash
uv run uvicorn main:app --reload # NecessÃ¡rio api estar em execuÃ§Ã£o
streamlit run dashboard/app.py 
```
DemonstraÃ§Ã£o do Dashboard
![DemonstraÃ§Ã£o do Dashboard de Livros](./assets/dashboard.png)

---

